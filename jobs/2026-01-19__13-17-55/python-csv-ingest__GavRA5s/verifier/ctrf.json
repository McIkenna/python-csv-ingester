{
    "results": {
        "tool": {
            "name": "pytest",
            "version": "8.4.1"
        },
        "summary": {
            "tests": 26,
            "passed": 0,
            "failed": 26,
            "skipped": 0,
            "pending": 0,
            "other": 0,
            "start": 1768850637.9186718,
            "stop": 1768850638.2349384
        },
        "tests": [
            {
                "name": "test_outputs.py::test_should_detect_utf8_encoding",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0037584170004265616,
                "start": 1768850637.9730947,
                "stop": 1768850637.9884179,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_should_detect_utf8_encoding(mock_test_data_two, solve_sh_path):\n        \"\"\"Test for encoding detection\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n                \"encoding-detection\",\n                f'\"{mock_test_data_two}\"',\n                solve_sh_path\n            )\n        assert returncode == 0\n>       assert \"utf\" in stdout.lower() or \"utf-8\" in stdout.lower()\nE       AssertionError: assert ('utf' in '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>' or 'utf-8' in '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>')\nE        +  where '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>' = <built-in method lower of str object at 0xffff8a6706f0>()\nE        +    where <built-in method lower of str object at 0xffff8a6706f0> = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'.lower\nE        +  and   '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>' = <built-in method lower of str object at 0xffff8a6706f0>()\nE        +    where <built-in method lower of str object at 0xffff8a6706f0> = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'.lower\n\n/tests/test_outputs.py:203: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_should_detect_latin_encoding",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0026494169997022254,
                "start": 1768850637.9885638,
                "stop": 1768850637.996406,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_latin1_data = '/tests/latin1_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_should_detect_latin_encoding(mock_latin1_data, solve_sh_path):\n        \"\"\"Test for encoding detection\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n                \"encoding-detection\",\n                f'\"{mock_latin1_data}\"',\n                solve_sh_path\n            )\n        assert returncode == 0\n>       assert \"latin\" in stdout.lower() or \"latin-1\" in stdout.lower()\nE       AssertionError: assert ('latin' in '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>' or 'latin-1' in '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>')\nE        +  where '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>' = <built-in method lower of str object at 0xffff8a670c90>()\nE        +    where <built-in method lower of str object at 0xffff8a670c90> = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'.lower\nE        +  and   '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>' = <built-in method lower of str object at 0xffff8a670c90>()\nE        +    where <built-in method lower of str object at 0xffff8a670c90> = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'.lower\n\n/tests/test_outputs.py:213: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_should_detect_encoding_nonexistent_file",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002569457999925362,
                "start": 1768850637.9965296,
                "stop": 1768850638.004323,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_should_detect_encoding_nonexistent_file(solve_sh_path):\n        \"\"\"Test with non-existent file\"\"\"\n        fake_file = os.path.join(TEST_DIR, \"nonexistent.csv\")\n        stdout, stderr, returncode = run_bash_command(\n            \"encoding-detection\",\n            f'\"{fake_file}\"',\n            solve_sh_path\n        )\n>       assert returncode != 0\nE       assert 0 != 0\n\n/tests/test_outputs.py:226: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_standardize_spaces_col_name",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002085542000713758,
                "start": 1768850638.0044472,
                "stop": 1768850638.0119202,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_standardize_spaces_col_name(solve_sh_path):\n            \"\"\"Test standardizing column with spaces\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"name-standardization\",\n                '\"Order Date\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           assert stdout.strip() == \"order_date\"\nE           AssertionError: assert '[output_file...ns <log_file>' == 'order_date'\nE             \nE             - order_date\nE             + [output_file]\nE             +   - dataframe-consolidation <output_file> <file1> <file2> ...\nE             +   - file-processing <output_file> <log_file> <file1> <file2> ...\nE             +   - cleaning-log [log_file]\nE             +   - csv-summary <csv_file>\nE             +   - get-operations <log_file>\n\n/tests/test_outputs.py:236: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_standardize_any_special_chars",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002563459001976298,
                "start": 1768850638.0125127,
                "stop": 1768850638.0203683,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_standardize_any_special_chars(solve_sh_path):\n            \"\"\"Test standardizing column with special characters\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"name-standardization\",\n                '\"Price $!!\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           assert stdout.strip() == \"price\"\nE           AssertionError: assert '[output_file...ns <log_file>' == 'price'\nE             \nE             - price\nE             + [output_file]\nE             +   - dataframe-consolidation <output_file> <file1> <file2> ...\nE             +   - file-processing <output_file> <log_file> <file1> <file2> ...\nE             +   - cleaning-log [log_file]\nE             +   - csv-summary <csv_file>\nE             +   - get-operations <log_file>\n\n/tests/test_outputs.py:246: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_standardize_any_casing",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0021928339992882684,
                "start": 1768850638.020473,
                "stop": 1768850638.0277412,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_standardize_any_casing(solve_sh_path):\n            \"\"\"Test standardizing column with special characters\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"name-standardization\",\n                '\"ProductPrice\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           assert stdout.strip() == \"product_price\"\nE           AssertionError: assert '[output_file...ns <log_file>' == 'product_price'\nE             \nE             - product_price\nE             + [output_file]\nE             +   - dataframe-consolidation <output_file> <file1> <file2> ...\nE             +   - file-processing <output_file> <log_file> <file1> <file2> ...\nE             +   - cleaning-log [log_file]\nE             +   - csv-summary <csv_file>\nE             +   - get-operations <log_file>\n\n/tests/test_outputs.py:256: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_detect_numeric_column",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003082125998844276,
                "start": 1768850638.0278487,
                "stop": 1768850638.0376103,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_detect_numeric_column(mock_test_data, solve_sh_path):\n            \"\"\"Test detection of numeric column\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"type-detection\",\n                f'\"{mock_test_data}\" \"Product Price $\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           assert stdout.strip() == \"numeric\"\nE           AssertionError: assert '[output_file...ns <log_file>' == 'numeric'\nE             \nE             - numeric\nE             + [output_file]\nE             +   - dataframe-consolidation <output_file> <file1> <file2> ...\nE             +   - file-processing <output_file> <log_file> <file1> <file2> ...\nE             +   - cleaning-log [log_file]\nE             +   - csv-summary <csv_file>\nE             +   - get-operations <log_file>\n\n/tests/test_outputs.py:270: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_detect_date_column",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0057969579993368825,
                "start": 1768850638.0377665,
                "stop": 1768850638.049264,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_detect_date_column(mock_test_data_two, solve_sh_path):\n        \"\"\"Test detection of date column\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"type-detection\",\n            f'\"{mock_test_data_two}\" \"Last Restock\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       assert stdout.strip() == \"date\"\nE       AssertionError: assert '[output_file...ns <log_file>' == 'date'\nE         \nE         - date\nE         + [output_file]\nE         +   - dataframe-consolidation <output_file> <file1> <file2> ...\nE         +   - file-processing <output_file> <log_file> <file1> <file2> ...\nE         +   - cleaning-log [log_file]\nE         +   - csv-summary <csv_file>\nE         +   - get-operations <log_file>\n\n/tests/test_outputs.py:280: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_detect_categorical_column",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0042829150006582495,
                "start": 1768850638.0494082,
                "stop": 1768850638.0593626,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_detect_categorical_column(mock_test_data_two, solve_sh_path):\n        \"\"\"Test detection of categorical column\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"type-detection\",\n            f'\"{mock_test_data_two}\" \"Supplier\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       assert stdout.strip() == \"categorical\"\nE       AssertionError: assert '[output_file...ns <log_file>' == 'categorical'\nE         \nE         - categorical\nE         + [output_file]\nE         +   - dataframe-consolidation <output_file> <file1> <file2> ...\nE         +   - file-processing <output_file> <log_file> <file1> <file2> ...\nE         +   - cleaning-log [log_file]\nE         +   - csv-summary <csv_file>\nE         +   - get-operations <log_file>\n\n/tests/test_outputs.py:290: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_detect_nonexistent_column",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002317873997526476,
                "start": 1768850638.059492,
                "stop": 1768850638.0670793,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_three = '/tests/test3_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_detect_nonexistent_column(mock_test_data_three, solve_sh_path):\n        \"\"\"Test with non-existent column\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"type-detection\",\n            f'\"{mock_test_data_three}\" \"NonExistent\"',\n            solve_sh_path\n        )\n>       assert returncode == 1\nE       assert 0 == 1\n\n/tests/test_outputs.py:299: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_parse_iso_dates",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0025579169996490236,
                "start": 1768850638.0671906,
                "stop": 1768850638.0773134,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_parse_iso_dates(mock_test_data, solve_sh_path):\n            \"\"\"Test parsing of ISO format dates\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"date-parsing\",\n                f'\"{mock_test_data}\" \"Order Date\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n            # Should return JSON array\n>           dates = extract_json_from_output(stdout)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:316: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_parse_mixed_date_formats",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0018937499989988282,
                "start": 1768850638.077423,
                "stop": 1768850638.0872054,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_parse_mixed_date_formats( mock_test_data_two, solve_sh_path):\n        \"\"\"Test parsing of mixed date formats\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"date-parsing\",\n            f'\"{mock_test_data_two}\" \"Last Restock\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       dates = extract_json_from_output(stdout)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_clip_numeric_outliers",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002278832998854341,
                "start": 1768850638.08731,
                "stop": 1768850638.097335,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_clip_numeric_outliers(mock_test_data, solve_sh_path):\n        print('solve_sh_path:', solve_sh_path)\n        \"\"\"Test clipping of numeric outliers\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"outlier-truncate\",\n            f'\"{mock_test_data}\" \"Total Amount\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       result = extract_json_from_output(stdout)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:346: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_clean_single_dataframe",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0019453749991953373,
                "start": 1768850638.0974524,
                "stop": 1768850638.1045282,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_clean_single_dataframe(mock_test_data, solve_sh_path):\n        \"\"\"Test cleaning of entire dataframe\"\"\"\n        output_file = os.path.join(TEST_DIR, 'cleaned_output.csv')\n        if os.path.exists(output_file):\n            os.remove(output_file)\n    \n        stdout, stderr, returncode = run_bash_command(\n            \"dataframe-cleaning\",\n            f'\"{mock_test_data}\" \"{output_file}\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       assert os.path.exists(output_file)\nE       AssertionError: assert False\nE        +  where False = <function exists at 0xffff8ba27420>('/tests/cleaned_output.csv')\nE        +    where <function exists at 0xffff8ba27420> = <module 'posixpath' (frozen)>.exists\nE        +      where <module 'posixpath' (frozen)> = os.path\n\n/tests/test_outputs.py:373: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_cleaned_columns_standardized",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002032958998825052,
                "start": 1768850638.104623,
                "stop": 1768850638.1191962,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_cleaned_columns_standardized(mock_test_data, solve_sh_path):\n            \"\"\"Test that cleaned CSV has standardized column names\"\"\"\n            output_file = os.path.join(TEST_DIR, 'cleaned_output.csv')\n            stdout, stderr, returncode = run_bash_command(\n                \"dataframe-cleaning\",\n                f'\"{mock_test_data}\" \"{output_file}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           result = extract_json_from_output(stdout)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:392: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_consolidate_dataframes",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0019556659972295165,
                "start": 1768850638.1193187,
                "stop": 1768850638.1292164,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv'\nmock_test_data_two = '/tests/test2_data.csv'\nmock_test_data_three = '/tests/test3_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_consolidate_dataframes(mock_test_data, mock_test_data_two, mock_test_data_three, solve_sh_path):\n        \"\"\"Test consolidation of multiple dataframes\"\"\"\n        output_file = os.path.join(TEST_DIR, 'consolidated_output.csv')\n    \n        stdout, stderr, returncode = run_bash_command(\n            \"dataframe-consolidation\",\n            f'\"{output_file}\" \"{mock_test_data}\" \"{mock_test_data_two}\" \"{mock_test_data_three}\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       result = extract_json_from_output(stdout)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:418: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_process_full_pipeline",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0025524579996272223,
                "start": 1768850638.1293244,
                "stop": 1768850638.1397269,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv'\nmock_test_data_two = '/tests/test2_data.csv'\nmock_test_data_three = '/tests/test3_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_process_full_pipeline(mock_test_data, mock_test_data_two, mock_test_data_three, solve_sh_path):\n            \"\"\"Test the complete processing pipeline\"\"\"\n            output_file = os.path.join(TEST_DIR, \"final_output.csv\")\n            log_file = os.path.join(TEST_DIR, \"process_log.json\")\n    \n            stdout, stderr, returncode = run_bash_command(\n                \"file-processing\",\n                f'\"{output_file}\" \"{log_file}\" \"{mock_test_data}\" \"{mock_test_data_two}\" \"{mock_test_data_three}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n            # Parse the log output\n>           log = extract_json_from_output(stdout)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:444: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_process_log_contains_operations",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0027553319978324,
                "start": 1768850638.1398323,
                "stop": 1768850638.1503785,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_process_log_contains_operations(mock_test_data_two,solve_sh_path):\n            \"\"\"Test that processing log contains expected operations\"\"\"\n            output_file = os.path.join(TEST_DIR, \"output.csv\")\n            log_file = os.path.join(TEST_DIR, \"log.json\")\n    \n            stdout, stderr, returncode = run_bash_command(\n                \"file-processing\",\n                f'\"{output_file}\" \"{log_file}\" \"{mock_test_data_two}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           log = extract_json_from_output(stdout)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:471: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_existing_operations",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003280458000517683,
                "start": 1768850638.1504922,
                "stop": 1768850638.161542,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_get_existing_operations(mock_test_data, solve_sh_path):\n    \n            output_file = os.path.join(TEST_DIR, \"output.csv\")\n            log_file = os.path.join(TEST_DIR, \"log.json\")\n    \n            # First, run processing to generate log\n            stdout, stderr, returncode = run_bash_command(\n                \"file-processing\",\n                f'\"{output_file}\" \"{log_file}\" \"{mock_test_data}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n            # Now, get existing operations\n            stdout, stderr, returncode = run_bash_command(\n                \"get-operations\",\n                f'\"{log_file}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           operations = extract_json_from_output(stdout)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:501: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_median_for_missing",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0024981259994092397,
                "start": 1768850638.161658,
                "stop": 1768850638.1721988,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_get_median_for_missing(mock_test_data, solve_sh_path):\n        \"\"\"Test to replace missing categorical values with 'Unknown'\"\"\"\n        output_file = os.path.join(TEST_DIR, 'output.csv')\n        log_file = os.path.join(TEST_DIR, \"log.json\")\n        if os.path.exists(output_file):\n            os.remove(output_file)\n        with open(mock_test_data, \"r\", encoding=\"utf-8\") as f:\n            reader = csv.reader(f)\n            headers = next(reader)\n            assert \"Product Price $\" in headers\n            empty_data_idx = headers.index(\"Product Price $\")\n            next(reader)\n            next(reader)\n            third_row = next(reader)\n            # test the value in the first data row\n            assert third_row[empty_data_idx] is None or third_row[empty_data_idx] == \"\"\n    \n        stdout, stderr, returncode = run_bash_command(\n            \"file-processing\",\n           f'\"{output_file}\" \"{log_file}\" \"{mock_test_data}\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       log = extract_json_from_output(stdout)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:534: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_unknown_for_missing",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0018874590004998026,
                "start": 1768850638.1723294,
                "stop": 1768850638.182276,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_get_unknown_for_missing(mock_test_data_two, solve_sh_path):\n        \"\"\"Test to replace missing categorical values with 'Unknown'\"\"\"\n        output_file = os.path.join(TEST_DIR, 'output.csv')\n        log_file = os.path.join(TEST_DIR, \"log.json\")\n        if os.path.exists(output_file):\n            os.remove(output_file)\n        with open(mock_test_data_two, \"r\", encoding=\"utf-8\") as f:\n            reader = csv.reader(f)\n            headers = next(reader)\n            assert \"Supplier\" in headers\n            empty_data_idx = headers.index(\"Supplier\")\n            # test the value in the first data row\n            first_row = next(reader)\n            assert first_row[empty_data_idx] == \"\"\n    \n        stdout, stderr, returncode = run_bash_command(\n            \"file-processing\",\n           f'\"{output_file}\" \"{log_file}\" \"{mock_test_data_two}\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       log = extract_json_from_output(stdout)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:582: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_cleaning_log",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003165125999657903,
                "start": 1768850638.182379,
                "stop": 1768850638.1932387,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_get_cleaning_log(mock_test_data, solve_sh_path):\n            \"\"\"Test retrieval of cleaning log\"\"\"\n            output_file = os.path.join(TEST_DIR, \"output.csv\")\n            log_file = os.path.join(TEST_DIR, \"log.json\")\n    \n            # First, run processing to generate log\n            stdout, stderr, returncode = run_bash_command(\n                \"file-processing\",\n                f'\"{output_file}\" \"{log_file}\" \"{mock_test_data}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n            # Now, get cleaning log\n            stdout, stderr, returncode = run_bash_command(\n                \"cleaning-log\",\n                f'\"{log_file}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           cleaning_log = extract_json_from_output(stdout)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:631: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_cleaning_log_nonexistent_file",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002170334000766161,
                "start": 1768850638.1933427,
                "stop": 1768850638.2032444,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_get_cleaning_log_nonexistent_file(solve_sh_path):\n            \"\"\"Test retrieval of cleaning log from non-existent file\"\"\"\n            fake_log_file = os.path.join(TEST_DIR, \"nonexistent_log.json\")\n    \n            stdout, stderr, returncode = run_bash_command(\n                \"cleaning-log\",\n                f'\"{fake_log_file}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           error_response = extract_json_from_output(stdout)\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:651: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_csv_summary",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.001905082997836871,
                "start": 1768850638.20336,
                "stop": 1768850638.214614,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_get_csv_summary(mock_test_data, solve_sh_path):\n    \n            # First, run processing to generate log\n            stdout, stderr, returncode = run_bash_command(\n                \"csv-summary\",\n                f'\"{mock_test_data}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           summary = extract_json_from_output(stdout)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:668: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_summary_shows_missing_values",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002111833999151713,
                "start": 1768850638.2147465,
                "stop": 1768850638.2248094,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_summary_shows_missing_values( mock_test_data_two, solve_sh_path):\n            \"\"\"Test that summary correctly identifies missing values\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"csv-summary\",\n                f'\"{mock_test_data_two}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           summary = extract_json_from_output(stdout)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:691: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_full_workflow",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002078167000945541,
                "start": 1768850638.2249198,
                "stop": 1768850638.2348392,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv'\nmock_test_data_two = '/tests/test2_data.csv'\nmock_test_data_three = '/tests/test3_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_full_workflow(mock_test_data, mock_test_data_two,  mock_test_data_three,\n                            solve_sh_path):\n        \"\"\"Test a complete workflow using multiple functions\"\"\"\n    \n        # 1. Get summary of input files\n        stdout1, _, _ = run_bash_command(\n            \"csv-summary\",\n            f'\"{mock_test_data}\"',\n            solve_sh_path\n        )\n>       summary1 = extract_json_from_output(stdout1)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:713: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  - dataframe-consolidation <output_file> <file1> <file2> ...\\n  - file-processing <output_file> <log_file> <file1> <file2> ...\\n  - cleaning-log [log_file]\\n  - csv-summary <csv_file>\\n  - get-operations <log_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            }
        ]
    }
}