{
    "results": {
        "tool": {
            "name": "pytest",
            "version": "8.4.1"
        },
        "summary": {
            "tests": 26,
            "passed": 0,
            "failed": 26,
            "skipped": 0,
            "pending": 0,
            "other": 0,
            "start": 1768840380.0025957,
            "stop": 1768840380.342513
        },
        "tests": [
            {
                "name": "test_outputs.py::test_should_detect_utf8_encoding",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.006355791000260069,
                "start": 1768840380.05532,
                "stop": 1768840380.072793,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_should_detect_utf8_encoding(mock_test_data_two, solve_sh_path):\n        \"\"\"Test for encoding detection\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n                \"encoding-detection\",\n                f'\"{mock_test_data_two}\"',\n                solve_sh_path\n            )\n        assert returncode == 0\n>       assert \"utf\" in stdout.lower() or \"utf-8\" in stdout.lower()\nE       AssertionError: assert ('utf' in '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>' or 'utf-8' in '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>')\nE        +  where '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>' = <built-in method lower of str object at 0xffff82ea4cf0>()\nE        +    where <built-in method lower of str object at 0xffff82ea4cf0> = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'.lower\nE        +  and   '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>' = <built-in method lower of str object at 0xffff82ea4cf0>()\nE        +    where <built-in method lower of str object at 0xffff82ea4cf0> = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'.lower\n\n/tests/test_outputs.py:203: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_should_detect_latin_encoding",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.005953083000349579,
                "start": 1768840380.0729427,
                "stop": 1768840380.0843685,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_latin1_data = '/tests/latin1_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_should_detect_latin_encoding(mock_latin1_data, solve_sh_path):\n        \"\"\"Test for encoding detection\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n                \"encoding-detection\",\n                f'\"{mock_latin1_data}\"',\n                solve_sh_path\n            )\n        assert returncode == 0\n>       assert \"latin\" in stdout.lower() or \"latin-1\" in stdout.lower()\nE       AssertionError: assert ('latin' in '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>' or 'latin-1' in '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>')\nE        +  where '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>' = <built-in method lower of str object at 0xffff82f41ac0>()\nE        +    where <built-in method lower of str object at 0xffff82f41ac0> = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'.lower\nE        +  and   '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>' = <built-in method lower of str object at 0xffff82f41ac0>()\nE        +    where <built-in method lower of str object at 0xffff82f41ac0> = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'.lower\n\n/tests/test_outputs.py:213: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_should_detect_encoding_nonexistent_file",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0031783330000507704,
                "start": 1768840380.084511,
                "stop": 1768840380.0930278,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_should_detect_encoding_nonexistent_file(solve_sh_path):\n        \"\"\"Test with non-existent file\"\"\"\n        fake_file = os.path.join(TEST_DIR, \"nonexistent.csv\")\n        stdout, stderr, returncode = run_bash_command(\n            \"encoding-detection\",\n            f'\"{fake_file}\"',\n            solve_sh_path\n        )\n>       assert returncode != 0\nE       assert 0 != 0\n\n/tests/test_outputs.py:226: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_standardize_spaces_col_name",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0028295419997448334,
                "start": 1768840380.093139,
                "stop": 1768840380.1015558,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_standardize_spaces_col_name(solve_sh_path):\n            \"\"\"Test standardizing column with spaces\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"name-standardization\",\n                '\"Order Date\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           assert stdout.strip() == \"order_date\"\nE           AssertionError: assert '[output_file...<output_file>' == 'order_date'\nE             \nE             - order_date\nE             + [output_file]\nE             +   dataframe-consolidation <output_file> <file1> <file2> ...\nE             +   file-processing <output_file> <log_file> <file1> <file2> ...\nE             +   cleaning-log [log_file]\nE             +   csv-summary <csv_file>\nE             +   get-operations <output_file>\n\n/tests/test_outputs.py:236: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_standardize_any_special_chars",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003100166999956855,
                "start": 1768840380.1016743,
                "stop": 1768840380.1101108,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_standardize_any_special_chars(solve_sh_path):\n            \"\"\"Test standardizing column with special characters\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"name-standardization\",\n                '\"Price $!!\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           assert stdout.strip() == \"price\"\nE           AssertionError: assert '[output_file...<output_file>' == 'price'\nE             \nE             - price\nE             + [output_file]\nE             +   dataframe-consolidation <output_file> <file1> <file2> ...\nE             +   file-processing <output_file> <log_file> <file1> <file2> ...\nE             +   cleaning-log [log_file]\nE             +   csv-summary <csv_file>\nE             +   get-operations <output_file>\n\n/tests/test_outputs.py:246: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_standardize_any_casing",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002842958000201179,
                "start": 1768840380.1102211,
                "stop": 1768840380.118183,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_standardize_any_casing(solve_sh_path):\n            \"\"\"Test standardizing column with special characters\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"name-standardization\",\n                '\"ProductPrice\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           assert stdout.strip() == \"product_price\"\nE           AssertionError: assert '[output_file...<output_file>' == 'product_price'\nE             \nE             - product_price\nE             + [output_file]\nE             +   dataframe-consolidation <output_file> <file1> <file2> ...\nE             +   file-processing <output_file> <log_file> <file1> <file2> ...\nE             +   cleaning-log [log_file]\nE             +   csv-summary <csv_file>\nE             +   get-operations <output_file>\n\n/tests/test_outputs.py:256: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_detect_numeric_column",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0030362080001395952,
                "start": 1768840380.118454,
                "stop": 1768840380.1267133,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_detect_numeric_column(mock_test_data, solve_sh_path):\n            \"\"\"Test detection of numeric column\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"type-detection\",\n                f'\"{mock_test_data}\" \"Product Price $\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           assert stdout.strip() == \"numeric\"\nE           AssertionError: assert '[output_file...<output_file>' == 'numeric'\nE             \nE             - numeric\nE             + [output_file]\nE             +   dataframe-consolidation <output_file> <file1> <file2> ...\nE             +   file-processing <output_file> <log_file> <file1> <file2> ...\nE             +   cleaning-log [log_file]\nE             +   csv-summary <csv_file>\nE             +   get-operations <output_file>\n\n/tests/test_outputs.py:270: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_detect_date_column",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003464166999947338,
                "start": 1768840380.1268208,
                "stop": 1768840380.1356573,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_detect_date_column(mock_test_data_two, solve_sh_path):\n        \"\"\"Test detection of date column\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"type-detection\",\n            f'\"{mock_test_data_two}\" \"Last Restock\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       assert stdout.strip() == \"date\"\nE       AssertionError: assert '[output_file...<output_file>' == 'date'\nE         \nE         - date\nE         + [output_file]\nE         +   dataframe-consolidation <output_file> <file1> <file2> ...\nE         +   file-processing <output_file> <log_file> <file1> <file2> ...\nE         +   cleaning-log [log_file]\nE         +   csv-summary <csv_file>\nE         +   get-operations <output_file>\n\n/tests/test_outputs.py:280: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_detect_categorical_column",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0030595000000630534,
                "start": 1768840380.135769,
                "stop": 1768840380.1441624,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_detect_categorical_column(mock_test_data_two, solve_sh_path):\n        \"\"\"Test detection of categorical column\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"type-detection\",\n            f'\"{mock_test_data_two}\" \"Supplier\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       assert stdout.strip() == \"categorical\"\nE       AssertionError: assert '[output_file...<output_file>' == 'categorical'\nE         \nE         - categorical\nE         + [output_file]\nE         +   dataframe-consolidation <output_file> <file1> <file2> ...\nE         +   file-processing <output_file> <log_file> <file1> <file2> ...\nE         +   cleaning-log [log_file]\nE         +   csv-summary <csv_file>\nE         +   get-operations <output_file>\n\n/tests/test_outputs.py:290: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_detect_nonexistent_column",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003222373999960837,
                "start": 1768840380.1444004,
                "stop": 1768840380.1525903,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_three = '/tests/test3_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_detect_nonexistent_column(mock_test_data_three, solve_sh_path):\n        \"\"\"Test with non-existent column\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"type-detection\",\n            f'\"{mock_test_data_three}\" \"NonExistent\"',\n            solve_sh_path\n        )\n>       assert returncode == 1\nE       assert 0 == 1\n\n/tests/test_outputs.py:299: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_parse_iso_dates",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003171917999679863,
                "start": 1768840380.1526961,
                "stop": 1768840380.1635165,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_parse_iso_dates(mock_test_data, solve_sh_path):\n            \"\"\"Test parsing of ISO format dates\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"date-parsing\",\n                f'\"{mock_test_data}\" \"Order Date\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n            # Should return JSON array\n>           dates = extract_json_from_output(stdout)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:316: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_parse_mixed_date_formats",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0026890000001458247,
                "start": 1768840380.163626,
                "stop": 1768840380.176182,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_parse_mixed_date_formats( mock_test_data_two, solve_sh_path):\n        \"\"\"Test parsing of mixed date formats\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"date-parsing\",\n            f'\"{mock_test_data_two}\" \"Last Restock\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       dates = extract_json_from_output(stdout)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:328: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_clip_numeric_outliers",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.005262666999897192,
                "start": 1768840380.1764545,
                "stop": 1768840380.1900544,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_clip_numeric_outliers(mock_test_data, solve_sh_path):\n        print('solve_sh_path:', solve_sh_path)\n        \"\"\"Test clipping of numeric outliers\"\"\"\n        stdout, stderr, returncode = run_bash_command(\n            \"outlier-truncate\",\n            f'\"{mock_test_data}\" \"Total Amount\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       result = extract_json_from_output(stdout)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:346: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_clean_single_dataframe",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.00332604199979869,
                "start": 1768840380.1901846,
                "stop": 1768840380.1988094,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_clean_single_dataframe(mock_test_data, solve_sh_path):\n        \"\"\"Test cleaning of entire dataframe\"\"\"\n        output_file = os.path.join(TEST_DIR, 'cleaned_output.csv')\n        if os.path.exists(output_file):\n            os.remove(output_file)\n    \n        stdout, stderr, returncode = run_bash_command(\n            \"dataframe-cleaning\",\n            f'\"{mock_test_data}\" \"{output_file}\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       assert os.path.exists(output_file)\nE       AssertionError: assert False\nE        +  where False = <function exists at 0xffff842df420>('/tests/cleaned_output.csv')\nE        +    where <function exists at 0xffff842df420> = <module 'posixpath' (frozen)>.exists\nE        +      where <module 'posixpath' (frozen)> = os.path\n\n/tests/test_outputs.py:373: AssertionError",
                "message": "The test failed in the call phase due to an assertion error"
            },
            {
                "name": "test_outputs.py::test_cleaned_columns_standardized",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0037047079997591936,
                "start": 1768840380.1989174,
                "stop": 1768840380.2155504,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_cleaned_columns_standardized(mock_test_data, solve_sh_path):\n            \"\"\"Test that cleaned CSV has standardized column names\"\"\"\n            output_file = os.path.join(TEST_DIR, 'cleaned_output.csv')\n            stdout, stderr, returncode = run_bash_command(\n                \"dataframe-cleaning\",\n                f'\"{mock_test_data}\" \"{output_file}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n>           result = extract_json_from_output(stdout)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:392: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_consolidate_dataframes",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.004455042000017784,
                "start": 1768840380.2156613,
                "stop": 1768840380.228776,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv'\nmock_test_data_two = '/tests/test2_data.csv'\nmock_test_data_three = '/tests/test3_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_consolidate_dataframes(mock_test_data, mock_test_data_two, mock_test_data_three, solve_sh_path):\n        \"\"\"Test consolidation of multiple dataframes\"\"\"\n        output_file = os.path.join(TEST_DIR, 'consolidated_output.csv')\n    \n        stdout, stderr, returncode = run_bash_command(\n            \"dataframe-consolidation\",\n            f'\"{output_file}\" \"{mock_test_data}\" \"{mock_test_data_two}\" \"{mock_test_data_three}\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       result = extract_json_from_output(stdout)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:418: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_process_full_pipeline",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0030380410000816482,
                "start": 1768840380.2288833,
                "stop": 1768840380.2400231,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv'\nmock_test_data_two = '/tests/test2_data.csv'\nmock_test_data_three = '/tests/test3_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_process_full_pipeline(mock_test_data, mock_test_data_two, mock_test_data_three, solve_sh_path):\n            \"\"\"Test the complete processing pipeline\"\"\"\n            output_file = os.path.join(TEST_DIR, \"final_output.csv\")\n            log_file = os.path.join(TEST_DIR, \"process_log.json\")\n    \n            stdout, stderr, returncode = run_bash_command(\n                \"file-processing\",\n                f'\"{output_file}\" \"{log_file}\" \"{mock_test_data}\" \"{mock_test_data_two}\" \"{mock_test_data_three}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n            # Parse the log output\n>           log = extract_json_from_output(stdout)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:444: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_process_log_contains_operations",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003347916999928202,
                "start": 1768840380.2401264,
                "stop": 1768840380.2508526,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_process_log_contains_operations(mock_test_data_two,solve_sh_path):\n            \"\"\"Test that processing log contains expected operations\"\"\"\n            output_file = os.path.join(TEST_DIR, \"output.csv\")\n            log_file = os.path.join(TEST_DIR, \"log.json\")\n    \n            stdout, stderr, returncode = run_bash_command(\n                \"file-processing\",\n                f'\"{output_file}\" \"{log_file}\" \"{mock_test_data_two}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           log = extract_json_from_output(stdout)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:471: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_existing_operations",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0042277079999166745,
                "start": 1768840380.2509604,
                "stop": 1768840380.2628226,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_get_existing_operations(mock_test_data, solve_sh_path):\n    \n            output_file = os.path.join(TEST_DIR, \"output.csv\")\n            log_file = os.path.join(TEST_DIR, \"log.json\")\n    \n            # First, run processing to generate log\n            stdout, stderr, returncode = run_bash_command(\n                \"file-processing\",\n                f'\"{output_file}\" \"{log_file}\" \"{mock_test_data}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n            # Now, get existing operations\n            stdout, stderr, returncode = run_bash_command(\n                \"get-operations\",\n                f'\"{log_file}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           operations = extract_json_from_output(stdout)\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:501: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_median_for_missing",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.002685500000097818,
                "start": 1768840380.2629375,
                "stop": 1768840380.2758968,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_get_median_for_missing(mock_test_data, solve_sh_path):\n        \"\"\"Test to replace missing categorical values with 'Unknown'\"\"\"\n        output_file = os.path.join(TEST_DIR, 'output.csv')\n        log_file = os.path.join(TEST_DIR, \"log.json\")\n        if os.path.exists(output_file):\n            os.remove(output_file)\n        with open(mock_test_data, \"r\", encoding=\"utf-8\") as f:\n            reader = csv.reader(f)\n            headers = next(reader)\n            assert \"Product Price $\" in headers\n            empty_data_idx = headers.index(\"Product Price $\")\n            next(reader)\n            next(reader)\n            third_row = next(reader)\n            # test the value in the first data row\n            assert third_row[empty_data_idx] is None or third_row[empty_data_idx] == \"\"\n    \n        stdout, stderr, returncode = run_bash_command(\n            \"file-processing\",\n           f'\"{output_file}\" \"{log_file}\" \"{mock_test_data}\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       log = extract_json_from_output(stdout)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:534: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_unknown_for_missing",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.00293070800012174,
                "start": 1768840380.2760005,
                "stop": 1768840380.2868922,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_get_unknown_for_missing(mock_test_data_two, solve_sh_path):\n        \"\"\"Test to replace missing categorical values with 'Unknown'\"\"\"\n        output_file = os.path.join(TEST_DIR, 'output.csv')\n        log_file = os.path.join(TEST_DIR, \"log.json\")\n        if os.path.exists(output_file):\n            os.remove(output_file)\n        with open(mock_test_data_two, \"r\", encoding=\"utf-8\") as f:\n            reader = csv.reader(f)\n            headers = next(reader)\n            assert \"Supplier\" in headers\n            empty_data_idx = headers.index(\"Supplier\")\n            # test the value in the first data row\n            first_row = next(reader)\n            assert first_row[empty_data_idx] == \"\"\n    \n        stdout, stderr, returncode = run_bash_command(\n            \"file-processing\",\n           f'\"{output_file}\" \"{log_file}\" \"{mock_test_data_two}\"',\n            solve_sh_path\n        )\n        assert returncode == 0\n>       log = extract_json_from_output(stdout)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:582: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_cleaning_log",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.004982667000149377,
                "start": 1768840380.286998,
                "stop": 1768840380.299777,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_get_cleaning_log(mock_test_data, solve_sh_path):\n            \"\"\"Test retrieval of cleaning log\"\"\"\n            output_file = os.path.join(TEST_DIR, \"output.csv\")\n            log_file = os.path.join(TEST_DIR, \"log.json\")\n    \n            # First, run processing to generate log\n            stdout, stderr, returncode = run_bash_command(\n                \"file-processing\",\n                f'\"{output_file}\" \"{log_file}\" \"{mock_test_data}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n            # Now, get cleaning log\n            stdout, stderr, returncode = run_bash_command(\n                \"cleaning-log\",\n                f'\"{log_file}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           cleaning_log = extract_json_from_output(stdout)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:631: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_cleaning_log_nonexistent_file",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0023709570000391977,
                "start": 1768840380.2998877,
                "stop": 1768840380.309872,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "solve_sh_path = 'solution/solve.sh'\n\n    def test_get_cleaning_log_nonexistent_file(solve_sh_path):\n            \"\"\"Test retrieval of cleaning log from non-existent file\"\"\"\n            fake_log_file = os.path.join(TEST_DIR, \"nonexistent_log.json\")\n    \n            stdout, stderr, returncode = run_bash_command(\n                \"cleaning-log\",\n                f'\"{fake_log_file}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           error_response = extract_json_from_output(stdout)\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:651: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_get_csv_summary",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003172082999981285,
                "start": 1768840380.3099773,
                "stop": 1768840380.3208318,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'\n\n    def test_get_csv_summary(mock_test_data, solve_sh_path):\n    \n            # First, run processing to generate log\n            stdout, stderr, returncode = run_bash_command(\n                \"csv-summary\",\n                f'\"{mock_test_data}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           summary = extract_json_from_output(stdout)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:668: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_summary_shows_missing_values",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.003151709000349001,
                "start": 1768840380.3209407,
                "stop": 1768840380.331819,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data_two = '/tests/test2_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_summary_shows_missing_values( mock_test_data_two, solve_sh_path):\n            \"\"\"Test that summary correctly identifies missing values\"\"\"\n            stdout, stderr, returncode = run_bash_command(\n                \"csv-summary\",\n                f'\"{mock_test_data_two}\"',\n                solve_sh_path\n            )\n            assert returncode == 0\n    \n>           summary = extract_json_from_output(stdout)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:691: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            },
            {
                "name": "test_outputs.py::test_full_workflow",
                "status": "failed",
                "raw_status": "call_failed",
                "duration": 0.0029925410001396813,
                "start": 1768840380.3319242,
                "stop": 1768840380.3421824,
                "retries": 0,
                "file_path": "test_outputs.py",
                "trace": "mock_test_data = '/tests/test_data.csv'\nmock_test_data_two = '/tests/test2_data.csv'\nmock_test_data_three = '/tests/test3_data.csv'\nsolve_sh_path = 'solution/solve.sh'\n\n    def test_full_workflow(mock_test_data, mock_test_data_two,  mock_test_data_three,\n                            solve_sh_path):\n        \"\"\"Test a complete workflow using multiple functions\"\"\"\n    \n        # 1. Get summary of input files\n        stdout1, _, _ = run_bash_command(\n            \"csv-summary\",\n            f'\"{mock_test_data}\"',\n            solve_sh_path\n        )\n>       summary1 = extract_json_from_output(stdout1)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n/tests/test_outputs.py:713: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\noutput = '[output_file]\\n  dataframe-consolidation <output_file> <file1> <file2> ...\\n  file-processing <output_file> <log_file> <file1> <file2> ...\\n  cleaning-log [log_file]\\n  csv-summary <csv_file>\\n  get-operations <output_file>'\n\n    def extract_json_from_output(output):\n        \"\"\"Extract JSON from output that may contain other text\"\"\"\n        try:\n            return json.loads(output)\n        except json.JSONDecodeError:\n            pass\n    \n        # Try to find JSON starting with { or [\n        for start_char in ['{', '[']:\n            start_idx = output.find(start_char)\n            if start_idx != -1:\n                depth = 0\n                end_char = '}' if start_char == '{' else ']'\n    \n                for i in range(start_idx, len(output)):\n                    if output[i] == start_char:\n                        depth += 1\n                    elif output[i] == end_char:\n                        depth -= 1\n                        if depth == 0:\n                            json_str = output[start_idx:i+1]\n                            try:\n                                return json.loads(json_str)\n                            except json.JSONDecodeError:\n                                continue\n    \n>       raise json.JSONDecodeError(\"No valid JSON found in output\", output, 0)\nE       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)\n\n/tests/test_outputs.py:58: JSONDecodeError",
                "message": "The test failed in the call phase"
            }
        ]
    }
}