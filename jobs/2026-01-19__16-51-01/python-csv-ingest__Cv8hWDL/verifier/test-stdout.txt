Hit:1 http://deb.debian.org/debian trixie InRelease
Hit:2 http://deb.debian.org/debian trixie-updates InRelease
Hit:3 http://deb.debian.org/debian-security trixie-security InRelease
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
curl is already the newest version (8.14.1-2+deb13u2).
0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.
no checksums to verify
installing to /root/.local/bin
  uv
  uvx
everything's installed!

To add $HOME/.local/bin to your PATH, either restart your shell or run:

    source $HOME/.local/bin/env (sh, bash, zsh)
    source $HOME/.local/bin/env.fish (fish)
============================= test session starts ==============================
platform linux -- Python 3.11.14, pytest-8.4.1, pluggy-1.6.0
rootdir: /tests
plugins: json-ctrf-0.3.5
collected 26 items

../tests/test_outputs.py FFFFFFFFFFFFFFFFFFFFFFFFFF                      [100%]

=================================== FAILURES ===================================
_______________________ test_should_detect_utf8_encoding _______________________

mock_test_data_two = '/tests/test2_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_should_detect_utf8_encoding(mock_test_data_two, solve_sh_path):
        """Test for encoding detection"""
    
    
        print(f"DEBUG: Current directory: {os.getcwd()}")
        print(f"DEBUG: Directory contents: {os.listdir('.')}")
        print(f"DEBUG: solve_sh_path: {solve_sh_path}")
        print(f"DEBUG: Absolute path: {os.path.abspath(solve_sh_path)}")
        stdout, stderr, returncode = run_bash_command(
                "encoding-detection",
                f'"{mock_test_data_two}"',
                solve_sh_path
            )
        assert returncode == 0
>       assert "utf" in stdout.lower() or "utf-8" in stdout.lower()
E       AssertionError: assert ('utf' in '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nusage: source solve.sh' or 'utf-8' in '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nusage: source solve.sh')
E        +  where '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nusage: source solve.sh' = <built-in method lower of str object at 0xffffb804c6f0>()
E        +    where <built-in method lower of str object at 0xffffb804c6f0> = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'.lower
E        +  and   '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nusage: source solve.sh' = <built-in method lower of str object at 0xffffb804c6f0>()
E        +    where <built-in method lower of str object at 0xffffb804c6f0> = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'.lower

/tests/test_outputs.py:219: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Current directory: /app
DEBUG: Directory contents: ['.pytest_cache', 'cleaning_log.json', 'solution', 'tests', 'cleaned_data.csv', 'src']
DEBUG: solve_sh_path: solution/solve.sh
DEBUG: Absolute path: /app/solution/solve.sh
DEBUG: Running command: solution/solve.sh encoding-detection "/tests/test2_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
______________________ test_should_detect_latin_encoding _______________________

mock_latin1_data = '/tests/latin1_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_should_detect_latin_encoding(mock_latin1_data, solve_sh_path):
        """Test for encoding detection"""
        stdout, stderr, returncode = run_bash_command(
                "encoding-detection",
                f'"{mock_latin1_data}"',
                solve_sh_path
            )
        assert returncode == 0
>       assert "latin" in stdout.lower() or "latin-1" in stdout.lower()
E       AssertionError: assert ('latin' in '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nusage: source solve.sh' or 'latin-1' in '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nusage: source solve.sh')
E        +  where '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nusage: source solve.sh' = <built-in method lower of str object at 0xffffb804ced0>()
E        +    where <built-in method lower of str object at 0xffffb804ced0> = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'.lower
E        +  and   '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nusage: source solve.sh' = <built-in method lower of str object at 0xffffb804ced0>()
E        +    where <built-in method lower of str object at 0xffffb804ced0> = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'.lower

/tests/test_outputs.py:229: AssertionError
---------------------------- Captured stdout setup -----------------------------
Created mock Latin-1 data file at: /tests/latin1_data.csv
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh encoding-detection "/tests/latin1_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_________________ test_should_detect_encoding_nonexistent_file _________________

solve_sh_path = 'solution/solve.sh'

    def test_should_detect_encoding_nonexistent_file(solve_sh_path):
        """Test with non-existent file"""
        fake_file = os.path.join(TEST_DIR, "nonexistent.csv")
        stdout, stderr, returncode = run_bash_command(
            "encoding-detection",
            f'"{fake_file}"',
            solve_sh_path
        )
>       assert returncode != 0
E       assert 0 != 0

/tests/test_outputs.py:242: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh encoding-detection "/tests/nonexistent.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_______________________ test_standardize_spaces_col_name _______________________

solve_sh_path = 'solution/solve.sh'

    def test_standardize_spaces_col_name(solve_sh_path):
            """Test standardizing column with spaces"""
            stdout, stderr, returncode = run_bash_command(
                "name-standardization",
                '"Order Date"',
                solve_sh_path
            )
            assert returncode == 0
>           assert stdout.strip() == "order_date"
E           AssertionError: assert '[output_file...urce solve.sh' == 'order_date'
E             
E             - order_date
E             + [output_file]
E             +   dataframe-consolidation <output_file> <file1> <file2> ...
E             +   file-processing <output_file> <log_file> <file1> <file2> ...
E             +   cleaning-log [log_file]
E             +   csv-summary <csv_file>...
E             
E             ...Full output truncated (3 lines hidden), use '-vv' to show

/tests/test_outputs.py:252: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh name-standardization "Order Date"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
______________________ test_standardize_any_special_chars ______________________

solve_sh_path = 'solution/solve.sh'

    def test_standardize_any_special_chars(solve_sh_path):
            """Test standardizing column with special characters"""
            stdout, stderr, returncode = run_bash_command(
                "name-standardization",
                '"Price $!!"',
                solve_sh_path
            )
            assert returncode == 0
>           assert stdout.strip() == "price"
E           AssertionError: assert '[output_file...urce solve.sh' == 'price'
E             
E             - price
E             + [output_file]
E             +   dataframe-consolidation <output_file> <file1> <file2> ...
E             +   file-processing <output_file> <log_file> <file1> <file2> ...
E             +   cleaning-log [log_file]
E             +   csv-summary <csv_file>...
E             
E             ...Full output truncated (3 lines hidden), use '-vv' to show

/tests/test_outputs.py:262: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh name-standardization "Price $!!"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_________________________ test_standardize_any_casing __________________________

solve_sh_path = 'solution/solve.sh'

    def test_standardize_any_casing(solve_sh_path):
            """Test standardizing column with special characters"""
            stdout, stderr, returncode = run_bash_command(
                "name-standardization",
                '"ProductPrice"',
                solve_sh_path
            )
            assert returncode == 0
>           assert stdout.strip() == "product_price"
E           AssertionError: assert '[output_file...urce solve.sh' == 'product_price'
E             
E             - product_price
E             + [output_file]
E             +   dataframe-consolidation <output_file> <file1> <file2> ...
E             +   file-processing <output_file> <log_file> <file1> <file2> ...
E             +   cleaning-log [log_file]
E             +   csv-summary <csv_file>...
E             
E             ...Full output truncated (3 lines hidden), use '-vv' to show

/tests/test_outputs.py:272: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh name-standardization "ProductPrice"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
__________________________ test_detect_numeric_column __________________________

mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_detect_numeric_column(mock_test_data, solve_sh_path):
            """Test detection of numeric column"""
            stdout, stderr, returncode = run_bash_command(
                "type-detection",
                f'"{mock_test_data}" "Product Price $"',
                solve_sh_path
            )
            assert returncode == 0
>           assert stdout.strip() == "numeric"
E           AssertionError: assert '[output_file...urce solve.sh' == 'numeric'
E             
E             - numeric
E             + [output_file]
E             +   dataframe-consolidation <output_file> <file1> <file2> ...
E             +   file-processing <output_file> <log_file> <file1> <file2> ...
E             +   cleaning-log [log_file]
E             +   csv-summary <csv_file>...
E             
E             ...Full output truncated (3 lines hidden), use '-vv' to show

/tests/test_outputs.py:286: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh type-detection "/tests/test_data.csv" "Product Price $"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
___________________________ test_detect_date_column ____________________________

mock_test_data_two = '/tests/test2_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_detect_date_column(mock_test_data_two, solve_sh_path):
        """Test detection of date column"""
        stdout, stderr, returncode = run_bash_command(
            "type-detection",
            f'"{mock_test_data_two}" "Last Restock"',
            solve_sh_path
        )
        assert returncode == 0
>       assert stdout.strip() == "date"
E       AssertionError: assert '[output_file...urce solve.sh' == 'date'
E         
E         - date
E         + [output_file]
E         +   dataframe-consolidation <output_file> <file1> <file2> ...
E         +   file-processing <output_file> <log_file> <file1> <file2> ...
E         +   cleaning-log [log_file]
E         +   csv-summary <csv_file>...
E         
E         ...Full output truncated (3 lines hidden), use '-vv' to show

/tests/test_outputs.py:296: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh type-detection "/tests/test2_data.csv" "Last Restock"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
________________________ test_detect_categorical_column ________________________

mock_test_data_two = '/tests/test2_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_detect_categorical_column(mock_test_data_two, solve_sh_path):
        """Test detection of categorical column"""
        stdout, stderr, returncode = run_bash_command(
            "type-detection",
            f'"{mock_test_data_two}" "Supplier"',
            solve_sh_path
        )
        assert returncode == 0
>       assert stdout.strip() == "categorical"
E       AssertionError: assert '[output_file...urce solve.sh' == 'categorical'
E         
E         - categorical
E         + [output_file]
E         +   dataframe-consolidation <output_file> <file1> <file2> ...
E         +   file-processing <output_file> <log_file> <file1> <file2> ...
E         +   cleaning-log [log_file]
E         +   csv-summary <csv_file>...
E         
E         ...Full output truncated (3 lines hidden), use '-vv' to show

/tests/test_outputs.py:306: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh type-detection "/tests/test2_data.csv" "Supplier"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
________________________ test_detect_nonexistent_column ________________________

mock_test_data_three = '/tests/test3_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_detect_nonexistent_column(mock_test_data_three, solve_sh_path):
        """Test with non-existent column"""
        stdout, stderr, returncode = run_bash_command(
            "type-detection",
            f'"{mock_test_data_three}" "NonExistent"',
            solve_sh_path
        )
>       assert returncode == 1
E       assert 0 == 1

/tests/test_outputs.py:315: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh type-detection "/tests/test3_data.csv" "NonExistent"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_____________________________ test_parse_iso_dates _____________________________

mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_parse_iso_dates(mock_test_data, solve_sh_path):
            """Test parsing of ISO format dates"""
            stdout, stderr, returncode = run_bash_command(
                "date-parsing",
                f'"{mock_test_data}" "Order Date"',
                solve_sh_path
            )
            assert returncode == 0
            # Should return JSON array
>           dates = extract_json_from_output(stdout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:332: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh date-parsing "/tests/test_data.csv" "Order Date"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
________________________ test_parse_mixed_date_formats _________________________

mock_test_data_two = '/tests/test2_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_parse_mixed_date_formats( mock_test_data_two, solve_sh_path):
        """Test parsing of mixed date formats"""
        stdout, stderr, returncode = run_bash_command(
            "date-parsing",
            f'"{mock_test_data_two}" "Last Restock"',
            solve_sh_path
        )
        assert returncode == 0
>       dates = extract_json_from_output(stdout)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:344: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh date-parsing "/tests/test2_data.csv" "Last Restock"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
__________________________ test_clip_numeric_outliers __________________________

mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_clip_numeric_outliers(mock_test_data, solve_sh_path):
        print('solve_sh_path:', solve_sh_path)
        """Test clipping of numeric outliers"""
        stdout, stderr, returncode = run_bash_command(
            "outlier-truncate",
            f'"{mock_test_data}" "Total Amount"',
            solve_sh_path
        )
        assert returncode == 0
>       result = extract_json_from_output(stdout)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:362: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
solve_sh_path: solution/solve.sh
DEBUG: Running command: solution/solve.sh outlier-truncate "/tests/test_data.csv" "Total Amount"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_________________________ test_clean_single_dataframe __________________________

mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_clean_single_dataframe(mock_test_data, solve_sh_path):
        """Test cleaning of entire dataframe"""
        output_file = os.path.join(TEST_DIR, 'cleaned_output.csv')
        if os.path.exists(output_file):
            os.remove(output_file)
    
        stdout, stderr, returncode = run_bash_command(
            "dataframe-cleaning",
            f'"{mock_test_data}" "{output_file}"',
            solve_sh_path
        )
        assert returncode == 0
>       assert os.path.exists(output_file)
E       AssertionError: assert False
E        +  where False = <function exists at 0xffffb93cf420>('/tests/cleaned_output.csv')
E        +    where <function exists at 0xffffb93cf420> = <module 'posixpath' (frozen)>.exists
E        +      where <module 'posixpath' (frozen)> = os.path

/tests/test_outputs.py:389: AssertionError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh dataframe-cleaning "/tests/test_data.csv" "/tests/cleaned_output.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
______________________ test_cleaned_columns_standardized _______________________

mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_cleaned_columns_standardized(mock_test_data, solve_sh_path):
            """Test that cleaned CSV has standardized column names"""
            output_file = os.path.join(TEST_DIR, 'cleaned_output.csv')
            stdout, stderr, returncode = run_bash_command(
                "dataframe-cleaning",
                f'"{mock_test_data}" "{output_file}"',
                solve_sh_path
            )
            assert returncode == 0
>           result = extract_json_from_output(stdout)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:408: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh dataframe-cleaning "/tests/test_data.csv" "/tests/cleaned_output.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_________________________ test_consolidate_dataframes __________________________

mock_test_data = '/tests/test_data.csv'
mock_test_data_two = '/tests/test2_data.csv'
mock_test_data_three = '/tests/test3_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_consolidate_dataframes(mock_test_data, mock_test_data_two, mock_test_data_three, solve_sh_path):
        """Test consolidation of multiple dataframes"""
        output_file = os.path.join(TEST_DIR, 'consolidated_output.csv')
    
        stdout, stderr, returncode = run_bash_command(
            "dataframe-consolidation",
            f'"{output_file}" "{mock_test_data}" "{mock_test_data_two}" "{mock_test_data_three}"',
            solve_sh_path
        )
        assert returncode == 0
>       result = extract_json_from_output(stdout)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:434: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh dataframe-consolidation "/tests/consolidated_output.csv" "/tests/test_data.csv" "/tests/test2_data.csv" "/tests/test3_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
__________________________ test_process_full_pipeline __________________________

mock_test_data = '/tests/test_data.csv'
mock_test_data_two = '/tests/test2_data.csv'
mock_test_data_three = '/tests/test3_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_process_full_pipeline(mock_test_data, mock_test_data_two, mock_test_data_three, solve_sh_path):
            """Test the complete processing pipeline"""
            output_file = os.path.join(TEST_DIR, "final_output.csv")
            log_file = os.path.join(TEST_DIR, "process_log.json")
    
            stdout, stderr, returncode = run_bash_command(
                "file-processing",
                f'"{output_file}" "{log_file}" "{mock_test_data}" "{mock_test_data_two}" "{mock_test_data_three}"',
                solve_sh_path
            )
            assert returncode == 0
    
            # Parse the log output
>           log = extract_json_from_output(stdout)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:460: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh file-processing "/tests/final_output.csv" "/tests/process_log.json" "/tests/test_data.csv" "/tests/test2_data.csv" "/tests/test3_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_____________________ test_process_log_contains_operations _____________________

mock_test_data_two = '/tests/test2_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_process_log_contains_operations(mock_test_data_two,solve_sh_path):
            """Test that processing log contains expected operations"""
            output_file = os.path.join(TEST_DIR, "output.csv")
            log_file = os.path.join(TEST_DIR, "log.json")
    
            stdout, stderr, returncode = run_bash_command(
                "file-processing",
                f'"{output_file}" "{log_file}" "{mock_test_data_two}"',
                solve_sh_path
            )
            assert returncode == 0
    
>           log = extract_json_from_output(stdout)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:487: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh file-processing "/tests/output.csv" "/tests/log.json" "/tests/test2_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_________________________ test_get_existing_operations _________________________

mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_get_existing_operations(mock_test_data, solve_sh_path):
    
            output_file = os.path.join(TEST_DIR, "output.csv")
            log_file = os.path.join(TEST_DIR, "log.json")
    
            # First, run processing to generate log
            stdout, stderr, returncode = run_bash_command(
                "file-processing",
                f'"{output_file}" "{log_file}" "{mock_test_data}"',
                solve_sh_path
            )
            assert returncode == 0
    
            # Now, get existing operations
            stdout, stderr, returncode = run_bash_command(
                "get-operations",
                f'"{log_file}"',
                solve_sh_path
            )
            assert returncode == 0
    
>           operations = extract_json_from_output(stdout)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:517: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh file-processing "/tests/output.csv" "/tests/log.json" "/tests/test_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
DEBUG: Running command: solution/solve.sh get-operations "/tests/log.json"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_________________________ test_get_median_for_missing __________________________

mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_get_median_for_missing(mock_test_data, solve_sh_path):
        """Test to replace missing categorical values with 'Unknown'"""
        output_file = os.path.join(TEST_DIR, 'output.csv')
        log_file = os.path.join(TEST_DIR, "log.json")
        if os.path.exists(output_file):
            os.remove(output_file)
        with open(mock_test_data, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            headers = next(reader)
            assert "Product Price $" in headers
            empty_data_idx = headers.index("Product Price $")
            next(reader)
            next(reader)
            third_row = next(reader)
            # test the value in the first data row
            assert third_row[empty_data_idx] is None or third_row[empty_data_idx] == ""
    
        stdout, stderr, returncode = run_bash_command(
            "file-processing",
           f'"{output_file}" "{log_file}" "{mock_test_data}"',
            solve_sh_path
        )
        assert returncode == 0
>       log = extract_json_from_output(stdout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:550: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh file-processing "/tests/output.csv" "/tests/log.json" "/tests/test_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_________________________ test_get_unknown_for_missing _________________________

mock_test_data_two = '/tests/test2_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_get_unknown_for_missing(mock_test_data_two, solve_sh_path):
        """Test to replace missing categorical values with 'Unknown'"""
        output_file = os.path.join(TEST_DIR, 'output.csv')
        log_file = os.path.join(TEST_DIR, "log.json")
        if os.path.exists(output_file):
            os.remove(output_file)
        with open(mock_test_data_two, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            headers = next(reader)
            assert "Supplier" in headers
            empty_data_idx = headers.index("Supplier")
            # test the value in the first data row
            first_row = next(reader)
            assert first_row[empty_data_idx] == ""
    
        stdout, stderr, returncode = run_bash_command(
            "file-processing",
           f'"{output_file}" "{log_file}" "{mock_test_data_two}"',
            solve_sh_path
        )
        assert returncode == 0
>       log = extract_json_from_output(stdout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:598: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh file-processing "/tests/output.csv" "/tests/log.json" "/tests/test2_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
____________________________ test_get_cleaning_log _____________________________

mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_get_cleaning_log(mock_test_data, solve_sh_path):
            """Test retrieval of cleaning log"""
            output_file = os.path.join(TEST_DIR, "output.csv")
            log_file = os.path.join(TEST_DIR, "log.json")
    
            # First, run processing to generate log
            stdout, stderr, returncode = run_bash_command(
                "file-processing",
                f'"{output_file}" "{log_file}" "{mock_test_data}"',
                solve_sh_path
            )
            assert returncode == 0
    
            # Now, get cleaning log
            stdout, stderr, returncode = run_bash_command(
                "cleaning-log",
                f'"{log_file}"',
                solve_sh_path
            )
            assert returncode == 0
    
>           cleaning_log = extract_json_from_output(stdout)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:647: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh file-processing "/tests/output.csv" "/tests/log.json" "/tests/test_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
DEBUG: Running command: solution/solve.sh cleaning-log "/tests/log.json"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
____________________ test_get_cleaning_log_nonexistent_file ____________________

solve_sh_path = 'solution/solve.sh'

    def test_get_cleaning_log_nonexistent_file(solve_sh_path):
            """Test retrieval of cleaning log from non-existent file"""
            fake_log_file = os.path.join(TEST_DIR, "nonexistent_log.json")
    
            stdout, stderr, returncode = run_bash_command(
                "cleaning-log",
                f'"{fake_log_file}"',
                solve_sh_path
            )
            assert returncode == 0
    
>           error_response = extract_json_from_output(stdout)
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:667: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh cleaning-log "/tests/nonexistent_log.json"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
_____________________________ test_get_csv_summary _____________________________

mock_test_data = '/tests/test_data.csv', solve_sh_path = 'solution/solve.sh'

    def test_get_csv_summary(mock_test_data, solve_sh_path):
    
            # First, run processing to generate log
            stdout, stderr, returncode = run_bash_command(
                "csv-summary",
                f'"{mock_test_data}"',
                solve_sh_path
            )
            assert returncode == 0
    
>           summary = extract_json_from_output(stdout)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:684: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh csv-summary "/tests/test_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
______________________ test_summary_shows_missing_values _______________________

mock_test_data_two = '/tests/test2_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_summary_shows_missing_values( mock_test_data_two, solve_sh_path):
            """Test that summary correctly identifies missing values"""
            stdout, stderr, returncode = run_bash_command(
                "csv-summary",
                f'"{mock_test_data_two}"',
                solve_sh_path
            )
            assert returncode == 0
    
>           summary = extract_json_from_output(stdout)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:707: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh csv-summary "/tests/test2_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
______________________________ test_full_workflow ______________________________

mock_test_data = '/tests/test_data.csv'
mock_test_data_two = '/tests/test2_data.csv'
mock_test_data_three = '/tests/test3_data.csv'
solve_sh_path = 'solution/solve.sh'

    def test_full_workflow(mock_test_data, mock_test_data_two,  mock_test_data_three,
                            solve_sh_path):
        """Test a complete workflow using multiple functions"""
    
        # 1. Get summary of input files
        stdout1, _, _ = run_bash_command(
            "csv-summary",
            f'"{mock_test_data}"',
            solve_sh_path
        )
>       summary1 = extract_json_from_output(stdout1)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/tests/test_outputs.py:729: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

output = '[output_file]\n  dataframe-consolidation <output_file> <file1> <file2> ...\n  file-processing <output_file> <log_file...file2> ...\n  cleaning-log [log_file]\n  csv-summary <csv_file>\n  get-operations <log_file>\n\nUsage: source solve.sh'

    def extract_json_from_output(output):
        """Extract JSON from output that may contain other text"""
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            pass
    
        # Try to find JSON starting with { or [
        for start_char in ['{', '[']:
            start_idx = output.find(start_char)
            if start_idx != -1:
                depth = 0
                end_char = '}' if start_char == '{' else ']'
    
                for i in range(start_idx, len(output)):
                    if output[i] == start_char:
                        depth += 1
                    elif output[i] == end_char:
                        depth -= 1
                        if depth == 0:
                            json_str = output[start_idx:i+1]
                            try:
                                return json.loads(json_str)
                            except json.JSONDecodeError:
                                continue
    
>       raise json.JSONDecodeError("No valid JSON found in output", output, 0)
E       json.decoder.JSONDecodeError: No valid JSON found in output: line 1 column 1 (char 0)

/tests/test_outputs.py:58: JSONDecodeError
----------------------------- Captured stdout call -----------------------------
DEBUG: Running command: solution/solve.sh csv-summary "/tests/test_data.csv"
DEBUG: File exists: True
DEBUG: File executable: True
DEBUG: Return code: 0
DEBUG: Stdout: 'CSV Ingester Shell Interface

Available commands:
  encoding-detection <filepath>
  name-standardization <column_name>
  type-detection <csv_file> <column_name>
  date-parsing <csv_file> <column_name>
  outlier-truncate <csv_file> <column_name>
  dataframe-cleaning <csv_file> [output_file]
  dataframe-consolidation <output_file> <file1> <file2> ...
  file-processing <output_file> <log_file> <file1> <file2> ...
  cleaning-log [log_file]
  csv-summary <csv_file>
  get-operations <log_file>

Usage: source solve.sh
'
DEBUG: Stderr: ''
=========================== short test summary info ============================
FAILED ../tests/test_outputs.py::test_should_detect_utf8_encoding - Assertion...
FAILED ../tests/test_outputs.py::test_should_detect_latin_encoding - Assertio...
FAILED ../tests/test_outputs.py::test_should_detect_encoding_nonexistent_file
FAILED ../tests/test_outputs.py::test_standardize_spaces_col_name - Assertion...
FAILED ../tests/test_outputs.py::test_standardize_any_special_chars - Asserti...
FAILED ../tests/test_outputs.py::test_standardize_any_casing - AssertionError...
FAILED ../tests/test_outputs.py::test_detect_numeric_column - AssertionError:...
FAILED ../tests/test_outputs.py::test_detect_date_column - AssertionError: as...
FAILED ../tests/test_outputs.py::test_detect_categorical_column - AssertionEr...
FAILED ../tests/test_outputs.py::test_detect_nonexistent_column - assert 0 == 1
FAILED ../tests/test_outputs.py::test_parse_iso_dates - json.decoder.JSONDeco...
FAILED ../tests/test_outputs.py::test_parse_mixed_date_formats - json.decoder...
FAILED ../tests/test_outputs.py::test_clip_numeric_outliers - json.decoder.JS...
FAILED ../tests/test_outputs.py::test_clean_single_dataframe - AssertionError...
FAILED ../tests/test_outputs.py::test_cleaned_columns_standardized - json.dec...
FAILED ../tests/test_outputs.py::test_consolidate_dataframes - json.decoder.J...
FAILED ../tests/test_outputs.py::test_process_full_pipeline - json.decoder.JS...
FAILED ../tests/test_outputs.py::test_process_log_contains_operations - json....
FAILED ../tests/test_outputs.py::test_get_existing_operations - json.decoder....
FAILED ../tests/test_outputs.py::test_get_median_for_missing - json.decoder.J...
FAILED ../tests/test_outputs.py::test_get_unknown_for_missing - json.decoder....
FAILED ../tests/test_outputs.py::test_get_cleaning_log - json.decoder.JSONDec...
FAILED ../tests/test_outputs.py::test_get_cleaning_log_nonexistent_file - jso...
FAILED ../tests/test_outputs.py::test_get_csv_summary - json.decoder.JSONDeco...
FAILED ../tests/test_outputs.py::test_summary_shows_missing_values - json.dec...
FAILED ../tests/test_outputs.py::test_full_workflow - json.decoder.JSONDecode...
============================== 26 failed in 0.36s ==============================
